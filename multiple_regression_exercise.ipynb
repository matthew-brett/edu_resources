{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-vacation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the modules we need\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# some extra modules for some useful types of plot\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-purchase",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Let's import the data we need. This is the ratemyprofessors dataset we looked at previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-slave",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://matthew-brett.github.io/cfd2019/data/rate_my_course.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-cooler",
   "metadata": {},
   "source": [
    "We are going to perform two linear regressions in this exercise.\n",
    "\n",
    "First, a simple linear regression (one predictor variable, one outcome variable) - we will predict 'Clarity' from 'Helpfulness'.\n",
    "\n",
    "Second, a multiple linear regression (several predictors, one outcome variable) - we will predict 'Clarity' from 'Easiness' and 'Helpfulness'.\n",
    "\n",
    "Create a dataframe called ```df_reg``` which contains only the variables we need for these regressions (Easiness, Helpfulness and Clarity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solar-mechanism",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = ...\n",
    "\n",
    "df_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "another-collective",
   "metadata": {},
   "source": [
    "# Simple Regression Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thousand-pillow",
   "metadata": {},
   "source": [
    "Before performing any sort of regression analysis, it is sensible to visually inspect the data.\n",
    "\n",
    "Create a scatterplot showing the relationship between 'Helpfulness' and 'Clarity'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-pressure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-restaurant",
   "metadata": {},
   "source": [
    "From visual inspection do you think there is a linear relationship between these variables?\n",
    "\n",
    "Let's perform a simple linear regression to see if your judgment is correct.\n",
    "\n",
    "Write a function, called ```sos_error_for_minimize()``` which takes as its input a list containing an intercept and a slope.\n",
    "\n",
    "```sos_error_for_minimize()``` should use the intercept and slope to predict Clarity rating scores from the Helpfulness rating scores stored in ```df_reg```. Remember: ```prediction = intercept + slope * predictor```.\n",
    "\n",
    "```sos_error_for_minimize()``` should then calculate the prediction errors by subtracting these predictions from the actual Clarity scores stored in ```df_reg```. It should return the sum of the squared prediction errors.\n",
    "\n",
    "<i> Hint: </i> you may find it helpful to refer to the 'Finding Lines' page here (https://matthew-brett.github.io/cfd2020/mean-slopes/finding_lines.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-referral",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sos_error_for_minimize(intercept_and_slope):\n",
    "   \n",
    "    intercept = ...\n",
    "    slope = ...\n",
    "    predicted = ...\n",
    "    error = ...\n",
    "    return ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developed-change",
   "metadata": {},
   "source": [
    "Run the cell below to check that your function is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-companion",
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_error_for_minimize([1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-current",
   "metadata": {},
   "source": [
    "Now use minimize, from the scipy library, to minimize the value of ```sos_error_for_minimize()```. Store the result in a variable called ```simple_reg```.\n",
    "\n",
    "<i> Hint: </i>  again, you may want to refer to the 'Finding Lines' page here (https://matthew-brett.github.io/cfd2020/mean-slopes/finding_lines.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-theta",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "simple_reg = minimize(...\n",
    "\n",
    "simple_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "individual-geography",
   "metadata": {},
   "source": [
    "## Using regression coefficients to generate predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pacific-calgary",
   "metadata": {},
   "source": [
    "The code in the cell below uses the intercept and slope - found by ```minimize``` - to generate predicted Clarity scores from the Helpfulness scores. \n",
    "\n",
    "These predictions are then plotted along with the actual Clarity scores. You can see that the predictions capture the general trend pretty well.\n",
    "\n",
    "<i> Hint: </i> paying attention to the first three lines of this code may help you later in the exercise..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-train",
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept = simple_reg.x[0]  # getting the intercept value from the output from minimize\n",
    "\n",
    "slope = simple_reg.x[1]      # getting the slope value for the predictor from the output from minimize\n",
    "\n",
    "predicted_values_simple_reg = intercept + df_reg['Helpfulness'] * slope   # generating the predictions\n",
    "\n",
    "\n",
    "# generating the scatter plot\n",
    "plt.scatter(df_reg['Helpfulness'], df_reg['Clarity'], label = 'actual values')\n",
    "plt.scatter(df_reg['Helpfulness'], predicted_values_simple_reg, label = 'predicted values')\n",
    "plt.xlabel('Helpfulness')\n",
    "plt.ylabel('Clarity')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-syndicate",
   "metadata": {},
   "source": [
    "# Moving to Multiple Regression\n",
    "\n",
    "Predicting the values of one outcome variable from one predictor variable is useful. However, often we are interested in the relationships between multiple variables. This brings us to multiple regression. \n",
    "\n",
    "Once again, before performing any analysis it is sensible to visually inspect the data.\n",
    "\n",
    "```pairplot()``` from the seaborn library is a useful function to inspect the relationship between multiple predictor variables and one outcome variable. It was imported at the start of this notebook using ```import seaborn as sns```. This function might be useful to you in your projects. \n",
    "\n",
    "The cell below contains code which generates a pairplot which shows Number of Professors and Clarity as the predictor (x) variables, and Overall Quality as the outcome (y) variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-tournament",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a pairplot\n",
    "\n",
    "sns.pairplot(data = df, x_vars = ['Number of Professors', 'Clarity'], y_vars = 'Overall Quality');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-placement",
   "metadata": {},
   "source": [
    "You can see that, from visual inspection, it looks like there is a strong linear relationship between Clarity and Overall Quality, but not between Number of Professors and Overall Quality.\n",
    "\n",
    "As mentioned earlier, for our multiple regression we are going to predict Clarity from Easiness and Helpfulness.\n",
    "\n",
    "Modify the ```sns.pairplot()``` code to generate a pairplot which uses 'Easiness' and 'Helpfulness' as the predictors (x_vars) and 'Clarity' as the outcome (y_vars)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "soviet-silence",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data = df, x_vars = ['Number of Professors', 'Clarity'], y_vars = 'Overall Quality');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprised-front",
   "metadata": {},
   "source": [
    "Do you think Easiness and Helpfulness look like they have a linear relationship with clarity?\n",
    "\n",
    "To show the relationship further, run the code in the cell below to generate a 3D scatter plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-canal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not worry about this code, it just generates a 3d plot\n",
    "\n",
    "fig = plt.figure(figsize = (10,8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(df_reg['Helpfulness'], df_reg['Easiness'], df_reg['Clarity'])\n",
    "plt.xlabel('Helpfulness Rating')\n",
    "plt.ylabel('Easiness Rating')\n",
    "ax.set_zlabel('Clarity Rating');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-conspiracy",
   "metadata": {},
   "source": [
    "# Multiple Regression\n",
    "\n",
    "The functions in the three cells below give us the machinery we need for multiple regression using ```minimize```. They are modified from the 'Simple and multiple regression' textbook page (https://matthew-brett.github.io/cfd2020/classification/single_multiple.html).\n",
    "\n",
    "Read the docstring and the comments in the cells and make sure you understand what each line of the function is doing. \n",
    "\n",
    "<b> Remember to run all three cells. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-money",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(intercept, slopes, row):\n",
    "    \"\"\" Predict a value given an intercept, slopes and corresponding row values\n",
    "    \"\"\"\n",
    "    return intercept + np.sum(slopes * np.array(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-webcam",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(intercept, slopes, attributes, y_values):\n",
    "    \"\"\" Root mean square error for prediction of `y_values` from `attributes`\n",
    "\n",
    "    Use `intercept` and `slopes` multiplied by `attributes` to give prediction.\n",
    "\n",
    "    `attributes` is a data frame with numerical attributes to predict from.\n",
    "    \"\"\"\n",
    "    errors = []  # create an empty list, to store the prediction errors\n",
    "    \n",
    "    for i in np.arange(len(y_values)):  # for every observation in the dataset (`i` is the index of the current observation)\n",
    "        \n",
    "        predicted = predict(intercept, slopes, attributes.iloc[i])  # call the predict() function and apply it to the\n",
    "                                                                    # current row of the attributes dataframe, using\n",
    "                                                                    # the intercept and slope values\n",
    "            \n",
    "        actual = y_values.iloc[i]        # get the actual value of the outcome variable for this observation\n",
    "        \n",
    "        errors.append((predicted - actual) ** 2)  # calculate the squared prediction error for this observation and\n",
    "                                                # append it to the 'errors' list\n",
    "            \n",
    "    return np.sqrt(np.mean(errors))   # return the square root of the average squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-lottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_for_params(params):\n",
    "    \"\"\" RMSE for intercept, slopes contained in `params`\n",
    "\n",
    "    `params[0]` is the intercept.  `params[1:]` are the slopes.\n",
    "    \"\"\"\n",
    "    intercept = params[0]  # store the first value of the 'params' list in a variable called 'intercept'\n",
    "    \n",
    "    slopes = params[1:]    # store the rest of the values in the 'params' list in a variable called 'slopes'\n",
    "        \n",
    "    return rmse(intercept, # call the rmse() function and return its output\n",
    "                slopes,\n",
    "                df_reg.loc[:, ['Easiness', 'Helpfulness']], # the values of the predictor variables\n",
    "                df_reg['Clarity']  # the values of the outcome variables\n",
    "               )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-permit",
   "metadata": {},
   "source": [
    "<i> Note: this way of doing things takes the predictor variable values and the outcome variable values from the 'top level' e.g. they are not given to the ```rmse_for_params()``` function as arguments. Therefore, this function wouldn't work if we were using different variables as the predictors or the outcome. We would need to write another function, or use the method shown in: https://matthew-brett.github.io/cfd2020/classification/Multiple_Regression.html </i>\n",
    "\n",
    "Use minimize to perform multiple linear regression, using the ```rmse_for_params()``` function. Predict Clarity from Easiness and Helpfulness. Store the result in a variable called ```min_multi_res```.\n",
    "\n",
    "\n",
    "<i> Hint: </i> you may find it helpful to refer to the 'Simple and multiple regression' textbook page here (https://matthew-brett.github.io/cfd2020/classification/single_multiple.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-midwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_multi_res = minimize(...\n",
    "                         \n",
    "min_multi_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-version",
   "metadata": {},
   "source": [
    "Now, get the values of the intercept and slopes and store these in separate variables.\n",
    "\n",
    "\n",
    "<i> Hint: </i> you may want to refer to the cell above entitled 'Using regression coefficients to generate predictions'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-belize",
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept = ...\n",
    "easiness_slope = ...\n",
    "helpfulness_slope = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-hudson",
   "metadata": {},
   "source": [
    "Use the intercept and slope variables you have just created to generate predicted Clarity scores from the Easiness and Helpfulness scores.\n",
    "\n",
    "Remember in for multiple regression: ```prediction = intercept + slope_1 * predictor_1 + slope_2 * predictor_2```\n",
    "\n",
    "In this case Easiness and Helpfulness are the predictors.\n",
    "\n",
    "<i> Hint: </i> again, you may want to refer to the cell above entitled 'Using regression coefficients to generate predictions'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-reward",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_values = intercept + ...\n",
    "\n",
    "predicted_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bulgarian-generation",
   "metadata": {},
   "source": [
    "The cell below plots the predicted values against the actual values. How well do you think multiple linear regression did at capturing the general trend in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-affiliate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not worry about this code, it just generates the 3D plot\n",
    "\n",
    "fig = plt.figure(figsize = (10,8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(df_reg['Helpfulness'], df_reg['Easiness'], df_reg['Clarity'], label = 'actual values')\n",
    "ax.scatter(df_reg['Helpfulness'], df_reg['Easiness'], predicted_values, label = 'predicted values', color = 'red')\n",
    "plt.legend()\n",
    "plt.xlabel('Helpfulness Rating')\n",
    "plt.ylabel('Easiness Rating')\n",
    "ax.set_zlabel('Clarity Rating');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-bidder",
   "metadata": {},
   "source": [
    "# Linear Regression with statsmodels\n",
    "\n",
    "We can also perform linear regression using functions from the statsmodels library.\n",
    "\n",
    "The cell below uses statsmodels to predict Clarity from Helpfulness, using linear regression. <i> Note: </i> this is the same simple linear regression we did earlier..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-signal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "simple_model_sm = smf.ols(formula=\"Clarity ~ Helpfulness\", data = df_reg) # create a model\n",
    "simple_fit_sm = simple_model_sm.fit() # fit the model\n",
    "simple_fit_sm.summary() # show the model summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-straight",
   "metadata": {},
   "source": [
    "Look at the intercept and slope values from statsmodels (shown in the table above under 'coef') . \n",
    "\n",
    "Let's compare those values to the intercept and slope values we got from our simple linear regression, where we predicted Clarity from Helpfulness using ```minimize```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-christian",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_reg.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-there",
   "metadata": {},
   "source": [
    "How similar/different are the slope and intercept values that statsmodels found from the ones we found using ```minimize```? Write your answer in the cell below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-economics",
   "metadata": {},
   "source": [
    "<i> Your answer here... </i>\n",
    "\n",
    "<i> Answer: the coefficients are the same. </i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "every-walnut",
   "metadata": {},
   "source": [
    "## Multiple Regression with Statsmodels\n",
    "\n",
    "Let's perform the same multiple regression we did above, but this time using statsmodels.\n",
    "\n",
    "Expanding on the statsmodels code presented above, use statsmodels to predict Clarity from Easiness and Helpfulness. Call the model ```multi_model_sm``` and called the fitted model ```multi_fit_sm```.\n",
    "\n",
    "<i> Hint: </i> you may want to refer to the 'Simple and multiple regression' textbook page here (https://matthew-brett.github.io/cfd2020/classification/single_multiple.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-ground",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_model_sm = ...\n",
    "multi_fit_sm = ...\n",
    "multi_fit_sm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-footwear",
   "metadata": {},
   "source": [
    "Again, look at the intercept and slope values from statsmodels (shown in the table above under 'coef') . \n",
    "\n",
    "Let's compare those values to the intercept and slope values we got from our multiple linear regression, where we predicted Clarity from Easiness and Helpfulness using ```minimize```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-injection",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_multi_res.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-roulette",
   "metadata": {},
   "source": [
    "How similar/different are the slope and intercept values that statsmodels found from the ones we found using ```minimize```? Write your answer in the cell below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "starting-omega",
   "metadata": {},
   "source": [
    "<i> Your answer here...\n",
    "\n",
    "Answer: the coefficients are the same. </i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-cutting",
   "metadata": {},
   "source": [
    "# Comparing statsmodels predictions to those from linear regression using minimize\n",
    "\n",
    "Just for fun, let's see how close the predictions are from each method of performing multiple linear regression (```minimize``` vs statsmodels).\n",
    "\n",
    "The ```.predict()``` method from statsmodels can be used to generate predictions from a model. The cell below uses this method to predict Easiness and Helpfulness from Clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-fitness",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = df_reg[['Easiness', 'Helpfulness']]\n",
    "sm_predictions = multi_fit_sm.predict(attributes)\n",
    "sm_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "false-eligibility",
   "metadata": {},
   "source": [
    "Let's take these predicted Clarity values from statsmodels, and subtract them from the predictions we got from multiple regression using minimize.\n",
    "\n",
    "If these values are small, it means the predictions from the two methods were very close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-fantasy",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimize_vs_sm = predicted_values - sm_predictions\n",
    "minimize_vs_sm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-above",
   "metadata": {},
   "source": [
    "Plot a histogram of the differences in the predictions between the two methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-beaver",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extreme-values",
   "metadata": {},
   "source": [
    "Calculate the mean difference between the predictions from the two methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-blind",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_difference_in_prediction = ...\n",
    "\n",
    "mean_difference_in_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positive-microphone",
   "metadata": {},
   "source": [
    "Finally, use ```np.count_nonzero()``` to count the number of differences in the predictions between the two methods which were larger than 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-forwarding",
   "metadata": {},
   "outputs": [],
   "source": [
    "less_than_point_zerozero_one = ...\n",
    "\n",
    "less_than_point_zerozero_one "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-recognition",
   "metadata": {},
   "source": [
    "Do you think the models are generating similar or different predictions? Why? Write your answer in the cell below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-electricity",
   "metadata": {},
   "source": [
    "<i> Your answer here... </i>\n",
    "\n",
    "<i> Answer: because the coefficients are the same for each method, the predictions are almost the same, so the difference between the predictions is very close to 0.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-communications",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
